{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e578e22-3d6b-4bed-ae12-19d5fc8bd285",
   "metadata": {
    "id": "9e578e22-3d6b-4bed-ae12-19d5fc8bd285"
   },
   "source": [
    "# Running the Sales Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9c65da9-f2a2-4962-a479-321d55b12e71",
   "metadata": {
    "id": "b9c65da9-f2a2-4962-a479-321d55b12e71"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "import create_prediction_df as prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e126c75-a43a-470d-ab04-fe7668741d89",
   "metadata": {
    "id": "5e126c75-a43a-470d-ab04-fe7668741d89"
   },
   "outputs": [],
   "source": [
    "def change_dtypes(df):\n",
    "    df['month'] = df['month'].astype(str)\n",
    "    df['quarter'] = df['quarter'].astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c0463e-36e8-463d-ab3f-4f8163b6e541",
   "metadata": {
    "id": "00c0463e-36e8-463d-ab3f-4f8163b6e541",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Palm Oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a91d8-5be8-4c33-8360-e7f4afcaccc2",
   "metadata": {
    "id": "cf4a91d8-5be8-4c33-8360-e7f4afcaccc2"
   },
   "outputs": [],
   "source": [
    "# SET ALL PARAMS HERE\n",
    "# Random state\n",
    "random_state = 42\n",
    "\n",
    "# Oils\n",
    "oil = 'PALM OIL'# Set oil type\n",
    "oil_file = 'data/palmoil_futures.csv'\n",
    "remove_scenario = 'purchase' # if you want to predict sales, remove purchase. if predicting purchase, remove sales.\n",
    "first_date = '2018-01-01' # Get data up to this date for prediction\n",
    "last_date = '2022-01-01' # Last date at which customer data will cut off, default first_date = '2020-01-01'\n",
    "\n",
    "# Set futures lookback params\n",
    "ema_lookback = [2] # 1 month and 2 months\n",
    "pct_lookback = [2] # 1 month and 2 months\n",
    "adv_months_list = [2] # futures to look at (in months) e.g. look at the contract 2 and 4 months from now\n",
    "\n",
    "# Set lag variable params\n",
    "lag = 2 # Set lag time, 2 = prediction for 2 months\n",
    "lags_by_variable = {'cust_lag': [lag],\n",
    "                   'oil_lag': [lag],\n",
    "                   'fx_lag': [lag],\n",
    "                   'sentiment_lag': [lag]} # all lags must be greater than initial lag period\n",
    "\n",
    "# Sentiment cols_to_keep\n",
    "sentiment_cols = ['crude oil', 'palm oil', 'ethanol', 'grains']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e4a3f5-1617-41da-973c-7f534807e8c8",
   "metadata": {
    "id": "a4e4a3f5-1617-41da-973c-7f534807e8c8"
   },
   "outputs": [],
   "source": [
    "def get_train_test_split(lag, oil, oil_file, first_date, last_date, ema_lookback, pct_lookback, adv_months_list, cols_to_keep):\n",
    "       # Set lag variable params\n",
    "    lags_by_variable = {'cust_lag': [lag],\n",
    "                       'oil_lag': [lag],\n",
    "                       'fx_lag': [lag],\n",
    "                       'sentiment_lag': [lag]} # all lags must be greater than initial lag period\n",
    "\n",
    "    # Generate df\n",
    "    # Generate customer df\n",
    "    all_cust_monthly_df = prep.get_lagged_customer_df(oil = oil, \n",
    "                                                      first_date = first_date, \n",
    "                                                      last_date = last_date, \n",
    "                                                      lags_by_variable = lags_by_variable, \n",
    "                                                      verbose = False)\n",
    "\n",
    "    # Generate oils and fx dfs\n",
    "    oils_df, crude_df, fx_df = prep.get_lagged_futures_df(oil_file = oil_file, \n",
    "                                                          first_date = first_date, \n",
    "                                                          last_date = last_date, \n",
    "                                                          lags_by_variable = lags_by_variable,\n",
    "                                                          ema_lookback = ema_lookback,\n",
    "                                                          pct_lookback = pct_lookback,\n",
    "                                                          adv_months_list = adv_months_list,\n",
    "                                                          verbose = False)\n",
    "\n",
    "    # Generate monthly sentiment df\n",
    "    sentiment = prep.get_sentiment_df(lags_by_variable = lags_by_variable, \n",
    "                                      cols_to_keep = sentiment_cols, \n",
    "                                      verbose = False)\n",
    "\n",
    "    # Merge all dfs\n",
    "    combined_df = prep.merge_dfs(all_cust_monthly_df = all_cust_monthly_df, \n",
    "                                 remove_scenario = remove_scenario, \n",
    "                                 oils_df = oils_df, \n",
    "                                 crude_df = crude_df, \n",
    "                                 fx_df = fx_df, \n",
    "                                 sentiment_df = sentiment, \n",
    "                                 verbose = True)\n",
    "\n",
    "    # Prediction prep\n",
    "    # Keep columes with 'lag'\n",
    "    pred = combined_df.copy()\n",
    "\n",
    "    # Remove columns unrelated to prediction\n",
    "    remove = [v for v in pred.columns if 'volume' in v] + [v for v in pred.columns if 'ema' in v] \n",
    "    other_cols = ['date'] + remove\n",
    "    pred = pred.drop(other_cols, axis = 1)\n",
    "\n",
    "    # Drop na\n",
    "    pred = pred.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    # pred.info()\n",
    "    print('Length before dropping na (lag rows): {}'.format(len(pred)))\n",
    "\n",
    "    pred = pred.dropna() # remove lag empty rows\n",
    "    print('Length after dropping na (lag rows): {}'.format(len(pred)))\n",
    "\n",
    "    # # Change data types\n",
    "    pred = change_dtypes(pred)\n",
    "    \n",
    "    # Define Train-Test split\n",
    "    Y = pred['sale'].astype(int)\n",
    "    cols_to_drop = ['sale', 'sales_on_month'] # remove highly correlated features manually\n",
    "    X = pred.drop(cols_to_drop, axis = 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a16afae-022d-4ca3-ae9b-a4d0a489e163",
   "metadata": {
    "id": "6a16afae-022d-4ca3-ae9b-a4d0a489e163",
    "outputId": "5ccbef96-c080-45b4-b19f-9cee8622ae73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Customer DF...\n",
      "Length of Customer DF: 49920\n",
      "Lagging customer variables...\n",
      "Lagged customer df of len 49920 has been created containing 1040 unique customers.\n",
      "Generating FUTURES DFs...\n",
      "Lagging variables...\n",
      "Created oils_df of length 48, crude_df of length 48 and fx_df of length 48.\n",
      "You are getting sentiment for: ['crude oil', 'palm oil', 'ethanol', 'grains']\n",
      "Created sentiment df of length 51\n",
      "Remove customer columns: ['%purchase_on_month', '%purchase_on_month_lag_2', 'purchase(t-1)_cust', 'purchases_on_month(t-1)_cust', 'purchase_quantity_on_month(t-1)_cust', 'cumulative_purchases_till_month(t-1)_cust', 'purchase_frequency(t-1)_cust', 'purchase_frequency_over_year(t-1)_cust', 'purchase_frequency_over_quarter(t-1)_cust', 'months_since_purchase(t-1)_cust', 'purchase', 'purchases_on_month', 'counter_party_code', 'commodity']\n",
      "Created combined_df for predection of len 49920 and first date 2018-01-31 00:00:00\n",
      "Length before dropping na (lag rows): 49920\n",
      "Length after dropping na (lag rows): 46800\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_split(lag = 1, # change this\n",
    "                                                        oil = oil, \n",
    "                                                        oil_file = oil_file, \n",
    "                                                        first_date =first_date, \n",
    "                                                        last_date = last_date,\n",
    "                                                        ema_lookback = ema_lookback, \n",
    "                                                        pct_lookback = pct_lookback, \n",
    "                                                        adv_months_list = adv_months_list, \n",
    "                                                        cols_to_keep = sentiment_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf55615-8d20-462c-892e-436fb15d2d61",
   "metadata": {
    "id": "fcf55615-8d20-462c-892e-436fb15d2d61",
    "outputId": "1c7f00ff-7558-4422-e2fe-74c999e179e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5517241379310346\n"
     ]
    }
   ],
   "source": [
    "# Load pickle model\n",
    "filename = 'best_model/palm_lgbm/lgbm_palm_1M.sav'\n",
    "best_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Make prediction and score\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print(test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8edd5b9-a6b7-4a13-b765-5357db0d2549",
   "metadata": {
    "id": "e8edd5b9-a6b7-4a13-b765-5357db0d2549",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Sunflower Oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f098f7-e4b6-421c-b57d-11e85187bb09",
   "metadata": {
    "id": "00f098f7-e4b6-421c-b57d-11e85187bb09"
   },
   "outputs": [],
   "source": [
    "# SET ALL PARAMS HERE\n",
    "# Random state\n",
    "random_state = 42\n",
    "\n",
    "# Oils\n",
    "oil = 'SUNFLOWER OIL'# Set oil type\n",
    "oil_file = 'data/sunfloweroil_futures.csv'\n",
    "remove_scenario = 'purchase' # if you want to predict sales, remove purchase. if predicting purchase, remove sales.\n",
    "first_date = '2018-01-01' # Get data up to this date for prediction\n",
    "last_date = '2022-01-01' # Last date at which customer data will cut off, default first_date = '2020-01-01'\n",
    "\n",
    "# Set futures lookback params\n",
    "ema_lookback = [2] # 1 month and 2 months\n",
    "pct_lookback = [2] # 1 month and 2 months\n",
    "adv_months_list = [2] # futures to look at (in months) e.g. look at the contract 2 and 4 months from now\n",
    "\n",
    "# Set lag variable params\n",
    "lag = 2 # Set lag time, 2 = prediction for 2 months\n",
    "lags_by_variable = {'cust_lag': [lag],\n",
    "                   'oil_lag': [lag],\n",
    "                   'fx_lag': [lag],\n",
    "                   'sentiment_lag': [lag]} # all lags must be greater than initial lag period\n",
    "\n",
    "# Sentiment cols_to_keep\n",
    "sentiment_cols = ['crude oil', 'crude oil_Count', 'sunflower oil', 'sunflower oil_Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2902fa-e585-4a04-bf6c-8eec6a1b6b16",
   "metadata": {
    "id": "5e2902fa-e585-4a04-bf6c-8eec6a1b6b16"
   },
   "outputs": [],
   "source": [
    "def get_train_test_split(lag, oil, oil_file, first_date, last_date, ema_lookback, pct_lookback, adv_months_list, cols_to_keep):\n",
    "       # Set lag variable params\n",
    "    lags_by_variable = {'cust_lag': [lag],\n",
    "                       'oil_lag': [lag],\n",
    "                       'fx_lag': [lag],\n",
    "                       'sentiment_lag': [lag]} # all lags must be greater than initial lag period\n",
    "\n",
    "    # Generate df\n",
    "    # Generate customer df\n",
    "    all_cust_monthly_df = prep.get_lagged_customer_df(oil = oil, \n",
    "                                                      first_date = first_date, \n",
    "                                                      last_date = last_date, \n",
    "                                                      lags_by_variable = lags_by_variable, \n",
    "                                                      verbose = False)\n",
    "\n",
    "    # Generate oils and fx dfs\n",
    "    oils_df, crude_df, fx_df = prep.get_lagged_futures_df(oil_file = oil_file, \n",
    "                                                          first_date = first_date, \n",
    "                                                          last_date = last_date, \n",
    "                                                          lags_by_variable = lags_by_variable,\n",
    "                                                          ema_lookback = ema_lookback,\n",
    "                                                          pct_lookback = pct_lookback,\n",
    "                                                          adv_months_list = adv_months_list,\n",
    "                                                          verbose = False)\n",
    "\n",
    "    # Generate monthly sentiment df\n",
    "    sentiment = prep.get_sentiment_df(lags_by_variable = lags_by_variable, \n",
    "                                      cols_to_keep = sentiment_cols, \n",
    "                                      verbose = False)\n",
    "\n",
    "    # Merge all dfs\n",
    "    combined_df = prep.merge_dfs(all_cust_monthly_df = all_cust_monthly_df, \n",
    "                                 remove_scenario = remove_scenario, \n",
    "                                 oils_df = oils_df, \n",
    "                                 crude_df = crude_df, \n",
    "                                 fx_df = fx_df, \n",
    "                                 sentiment_df = sentiment, \n",
    "                                 verbose = True)\n",
    "\n",
    "    # Prediction prep\n",
    "    # Keep columes with 'lag'\n",
    "    pred = combined_df.copy()\n",
    "\n",
    "    # Remove columns unrelated to prediction\n",
    "    remove =  [v for v in pred.columns if 'volume' in v] + [v for v in pred.columns if 'ema' in v] + [v for v in pred.columns if 'openinterest' in v] \n",
    "    other_cols = ['date'] + remove\n",
    "    pred = pred.drop(other_cols, axis = 1)\n",
    "\n",
    "    # Drop na\n",
    "    pred = pred.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    # pred.info()\n",
    "    print('Length before dropping na (lag rows): {}'.format(len(pred)))\n",
    "\n",
    "    pred = pred.dropna() # remove lag empty rows\n",
    "    print('Length after dropping na (lag rows): {}'.format(len(pred)))\n",
    "\n",
    "    # # Change data types\n",
    "    pred = change_dtypes(pred)\n",
    "    \n",
    "    # Define Train-Test split\n",
    "    Y = pred['sale'].astype(int)\n",
    "    cols_to_drop = ['sale', 'sales_on_month'] # remove highly correlated features manually\n",
    "    X = pred.drop(cols_to_drop, axis = 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e985f360-2fce-4ba2-8b16-e1e2dd93be3b",
   "metadata": {
    "id": "e985f360-2fce-4ba2-8b16-e1e2dd93be3b",
    "outputId": "1388c5e7-c46c-4310-cf85-7a04d84201d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Customer DF...\n",
      "Length of Customer DF: 53232\n",
      "Lagging customer variables...\n",
      "Lagged customer df of len 53232 has been created containing 1109 unique customers.\n",
      "Generating FUTURES DFs...\n",
      "Lagging variables...\n",
      "Created oils_df of length 48, crude_df of length 48 and fx_df of length 48.\n",
      "You are getting sentiment for: ['crude oil', 'crude oil_Count', 'sunflower oil', 'sunflower oil_Count']\n",
      "Created sentiment df of length 51\n",
      "Remove customer columns: ['%purchase_on_month', '%purchase_on_month_lag_2', 'purchase(t-2)_cust', 'purchases_on_month(t-2)_cust', 'purchase_quantity_on_month(t-2)_cust', 'cumulative_purchases_till_month(t-2)_cust', 'purchase_frequency(t-2)_cust', 'purchase_frequency_over_year(t-2)_cust', 'purchase_frequency_over_quarter(t-2)_cust', 'months_since_purchase(t-2)_cust', 'purchase', 'purchases_on_month', 'counter_party_code', 'commodity']\n",
      "Created combined_df for predection of len 53232 and first date 2018-01-31 00:00:00\n",
      "Length before dropping na (lag rows): 53232\n",
      "Length after dropping na (lag rows): 48796\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_split(lag = 2, # change this\n",
    "                                                        oil = oil, \n",
    "                                                        oil_file = oil_file, \n",
    "                                                        first_date =first_date, \n",
    "                                                        last_date = last_date,\n",
    "                                                        ema_lookback = ema_lookback, \n",
    "                                                        pct_lookback = pct_lookback, \n",
    "                                                        adv_months_list = adv_months_list, \n",
    "                                                        cols_to_keep = sentiment_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbdb83b-8117-4938-b157-a6fe5d5865ba",
   "metadata": {
    "id": "7dbdb83b-8117-4938-b157-a6fe5d5865ba",
    "outputId": "a256aa6c-d81b-4656-89c7-fd13f76e6d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46587658357172046\n"
     ]
    }
   ],
   "source": [
    "# Load pickle model\n",
    "filename = 'best_model/sunflower_lgbm/lgbm_sunflower_2M.sav'\n",
    "best_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Make prediction and score\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print(test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b2b4e-a3f5-4729-9632-01e6887e71c7",
   "metadata": {
    "id": "660b2b4e-a3f5-4729-9632-01e6887e71c7",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Rapeseed Oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6d6c4a-c3e5-4f6d-bb15-8c9ee7511d2a",
   "metadata": {
    "id": "cd6d6c4a-c3e5-4f6d-bb15-8c9ee7511d2a"
   },
   "outputs": [],
   "source": [
    "# SET ALL PARAMS HERE\n",
    "# Random state\n",
    "random_state = 42\n",
    "\n",
    "# Oils\n",
    "oil = 'RAPE OIL'# Set oil type\n",
    "oil_file = 'data/rapeseedoil_futures.csv'\n",
    "remove_scenario = 'purchase' # if you want to predict sales, remove purchase. if predicting purchase, remove sales.\n",
    "first_date = '2018-01-01' # Get data up to this date for prediction\n",
    "last_date = '2022-01-01' # Last date at which customer data will cut off, default first_date = '2020-01-01'\n",
    "\n",
    "# Set futures lookback params\n",
    "ema_lookback = [2] \n",
    "pct_lookback = [2] \n",
    "adv_months_list = [2] # futures to look at (in months) e.g. look at the contract 2 months from now\n",
    "\n",
    "# Set lag variable params\n",
    "lag = 2 # Set lag time, 2 = prediction for 2 months\n",
    "lags_by_variable = {'cust_lag': [lag],\n",
    "                   'oil_lag': [lag],\n",
    "                   'fx_lag': [lag],\n",
    "                   'sentiment_lag': [lag]} # all lags must be greater than initial lag period\n",
    "\n",
    "# Sentiment cols_to_keep\n",
    "sentiment_cols = ['crude oil', 'crude oil_Count', 'rapeseed oil', 'rapeseed oil_Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129581fa-d11b-4417-87ba-154f3b887266",
   "metadata": {
    "id": "129581fa-d11b-4417-87ba-154f3b887266"
   },
   "outputs": [],
   "source": [
    "def get_train_test_split(lag, oil, oil_file, first_date, last_date, ema_lookback, pct_lookback, adv_months_list, cols_to_keep):\n",
    "       # Set lag variable params\n",
    "    lags_by_variable = {'cust_lag': [lag],\n",
    "                       'oil_lag': [lag],\n",
    "                       'fx_lag': [lag],\n",
    "                       'sentiment_lag': [lag]} # all lags must be greater than initial lag period\n",
    "\n",
    "    # Generate df\n",
    "    # Generate customer df\n",
    "    all_cust_monthly_df = prep.get_lagged_customer_df(oil = oil, \n",
    "                                                      first_date = first_date, \n",
    "                                                      last_date = last_date, \n",
    "                                                      lags_by_variable = lags_by_variable, \n",
    "                                                      verbose = False)\n",
    "\n",
    "    # Generate oils and fx dfs\n",
    "    oils_df, crude_df, fx_df = prep.get_lagged_futures_df(oil_file = oil_file, \n",
    "                                                          first_date = first_date, \n",
    "                                                          last_date = last_date, \n",
    "                                                          lags_by_variable = lags_by_variable,\n",
    "                                                          ema_lookback = ema_lookback,\n",
    "                                                          pct_lookback = pct_lookback,\n",
    "                                                          adv_months_list = adv_months_list,\n",
    "                                                          verbose = False)\n",
    "\n",
    "    # Generate monthly sentiment df\n",
    "    sentiment = prep.get_sentiment_df(lags_by_variable = lags_by_variable, \n",
    "                                      cols_to_keep = sentiment_cols, \n",
    "                                      verbose = False)\n",
    "\n",
    "    # Merge all dfs\n",
    "    combined_df = prep.merge_dfs(all_cust_monthly_df = all_cust_monthly_df, \n",
    "                                 remove_scenario = remove_scenario, \n",
    "                                 oils_df = oils_df, \n",
    "                                 crude_df = crude_df, \n",
    "                                 fx_df = fx_df, \n",
    "                                 sentiment_df = sentiment, \n",
    "                                 verbose = True)\n",
    "\n",
    "    # Prediction prep\n",
    "    # Keep columes with 'lag'\n",
    "    pred = combined_df.copy()\n",
    "\n",
    "    # Remove columns unrelated to prediction\n",
    "    remove =  [v for v in pred.columns if 'volume' in v] + [v for v in pred.columns if 'ema' in v] + [v for v in pred.columns if 'openinterest' in v] \n",
    "    other_cols = ['date'] + remove\n",
    "    pred = pred.drop(other_cols, axis = 1)\n",
    "\n",
    "    # Drop na\n",
    "    pred = pred.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    # pred.info()\n",
    "    print('Length before dropping na (lag rows): {}'.format(len(pred)))\n",
    "\n",
    "    pred = pred.dropna() # remove lag empty rows\n",
    "    print('Length after dropping na (lag rows): {}'.format(len(pred)))\n",
    "\n",
    "    # # Change data types\n",
    "    pred = change_dtypes(pred)\n",
    "    \n",
    "    # Define Train-Test split\n",
    "    Y = pred['sale'].astype(int)\n",
    "    cols_to_drop = ['sale', 'sales_on_month'] # remove highly correlated features manually\n",
    "    X = pred.drop(cols_to_drop, axis = 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfea171-1aa6-4ea8-9ad8-f0a8a328a2ef",
   "metadata": {
    "id": "dbfea171-1aa6-4ea8-9ad8-f0a8a328a2ef",
    "outputId": "b4f37845-2c6d-43b3-d944-836dd5a45d77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Customer DF...\n",
      "Length of Customer DF: 31824\n",
      "Lagging customer variables...\n",
      "Lagged customer df of len 31824 has been created containing 663 unique customers.\n",
      "Generating FUTURES DFs...\n",
      "Lagging variables...\n",
      "Created oils_df of length 48, crude_df of length 48 and fx_df of length 48.\n",
      "You are getting sentiment for: ['crude oil', 'crude oil_Count', 'rapeseed oil', 'rapeseed oil_Count']\n",
      "Created sentiment df of length 51\n",
      "Remove customer columns: ['%purchase_on_month', '%purchase_on_month_lag_2', 'purchase(t-2)_cust', 'purchases_on_month(t-2)_cust', 'purchase_quantity_on_month(t-2)_cust', 'cumulative_purchases_till_month(t-2)_cust', 'purchase_frequency(t-2)_cust', 'purchase_frequency_over_year(t-2)_cust', 'purchase_frequency_over_quarter(t-2)_cust', 'months_since_purchase(t-2)_cust', 'purchase', 'purchases_on_month', 'counter_party_code', 'commodity']\n",
      "Created combined_df for predection of len 31824 and first date 2018-01-31 00:00:00\n",
      "Length before dropping na (lag rows): 31824\n",
      "Length after dropping na (lag rows): 28509\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_split(lag = 2, # change this\n",
    "                                                        oil = oil, \n",
    "                                                        oil_file = oil_file, \n",
    "                                                        first_date =first_date, \n",
    "                                                        last_date = last_date,\n",
    "                                                        ema_lookback = ema_lookback, \n",
    "                                                        pct_lookback = pct_lookback, \n",
    "                                                        adv_months_list = adv_months_list, \n",
    "                                                        cols_to_keep = sentiment_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb1a832-3965-4586-abfc-c6c3552c10a6",
   "metadata": {
    "id": "5bb1a832-3965-4586-abfc-c6c3552c10a6",
    "outputId": "59a574ee-559d-4e4c-f12c-33aeb621fae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5371655104063429\n"
     ]
    }
   ],
   "source": [
    "# Load pickle model\n",
    "filename = 'best_model/rapeseed_lgbm/lgbm_rapeseed_2M.sav'\n",
    "best_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Make prediction and score\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print(test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f89fab-5033-46e4-a4a5-a0b2d5bfab9a",
   "metadata": {
    "id": "35f89fab-5033-46e4-a4a5-a0b2d5bfab9a"
   },
   "source": [
    "## 4.Soybean Oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bee85c3-c24d-4ee3-86ee-26235708dca5",
   "metadata": {
    "id": "6bee85c3-c24d-4ee3-86ee-26235708dca5"
   },
   "outputs": [],
   "source": [
    "def get_train_test_split(lag, oil, oil_file, first_date, last_date, ema_lookback, pct_lookback, adv_months_list, cols_to_keep):\n",
    "       # Set lag variable params\n",
    "    lags_by_variable = {'cust_lag': [lag],\n",
    "                       'oil_lag': [lag],\n",
    "                       'fx_lag': [lag],\n",
    "                       'sentiment_lag': [lag]} # all lags must be greater than initial lag period\n",
    "\n",
    "    # Generate df\n",
    "    # Generate customer df\n",
    "    all_cust_monthly_df = prep.get_lagged_customer_df(oil = oil, \n",
    "                                                      first_date = first_date, \n",
    "                                                      last_date = last_date, \n",
    "                                                      lags_by_variable = lags_by_variable, \n",
    "                                                      verbose = False)\n",
    "\n",
    "    # Generate oils and fx dfs\n",
    "    oils_df, crude_df, fx_df = prep.get_lagged_futures_df(oil_file = oil_file, \n",
    "                                                          first_date = first_date, \n",
    "                                                          last_date = last_date, \n",
    "                                                          lags_by_variable = lags_by_variable,\n",
    "                                                          ema_lookback = ema_lookback,\n",
    "                                                          pct_lookback = pct_lookback,\n",
    "                                                          adv_months_list = adv_months_list,\n",
    "                                                          verbose = False)\n",
    "\n",
    "    # Generate monthly sentiment df\n",
    "    sentiment = prep.get_sentiment_df(lags_by_variable = lags_by_variable, \n",
    "                                      cols_to_keep = sentiment_cols, \n",
    "                                      verbose = False)\n",
    "\n",
    "    # Merge all dfs\n",
    "    combined_df = prep.merge_dfs(all_cust_monthly_df = all_cust_monthly_df, \n",
    "                                 remove_scenario = remove_scenario, \n",
    "                                 oils_df = oils_df, \n",
    "                                 crude_df = crude_df, \n",
    "                                 fx_df = fx_df, \n",
    "                                 sentiment_df = sentiment, \n",
    "                                 verbose = True)\n",
    "\n",
    "    # Prediction prep\n",
    "    # Keep columes with 'lag'\n",
    "    pred = combined_df.copy()\n",
    "\n",
    "    # Remove columns unrelated to prediction\n",
    "    remove = [v for v in pred.columns if 'volume' in v] + [v for v in pred.columns if 'ema' in v] \n",
    "    other_cols = ['date'] + remove\n",
    "    pred = pred.drop(other_cols, axis = 1)\n",
    "\n",
    "    # Drop na\n",
    "    pred = pred.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    # pred.info()\n",
    "    print('Length before dropping na (lag rows): {}'.format(len(pred)))\n",
    "\n",
    "    pred = pred.dropna() # remove lag empty rows\n",
    "    print('Length after dropping na (lag rows): {}'.format(len(pred)))\n",
    "\n",
    "    # # Change data types\n",
    "    pred = change_dtypes(pred)\n",
    "    \n",
    "    # Define Train-Test split\n",
    "    Y = pred['sale'].astype(int)\n",
    "    cols_to_drop = ['sale', 'sales_on_month'] # remove highly correlated features manually\n",
    "    X = pred.drop(cols_to_drop, axis = 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7965f0d5-986c-480a-9e60-75af57131369",
   "metadata": {
    "id": "7965f0d5-986c-480a-9e60-75af57131369"
   },
   "outputs": [],
   "source": [
    "# SET ALL PARAMS HERE\n",
    "# Random state\n",
    "random_state = 42\n",
    "\n",
    "# Oils\n",
    "oil = 'SOYBEAN OIL'# Set oil type\n",
    "oil_file = 'data/soyoil_futures.csv'\n",
    "remove_scenario = 'purchase' # if you want to predict sales, remove purchase. if predicting purchase, remove sales.\n",
    "first_date = '2018-01-01' # Get data up to this date for prediction\n",
    "last_date = '2022-01-01' # Last date at which customer data will cut off, default first_date = '2020-01-01'\n",
    "\n",
    "# Set futures lookback params\n",
    "ema_lookback = [2] # 1 month and 2 months\n",
    "pct_lookback = [2] # 1 month and 2 months\n",
    "adv_months_list = [2] # futures to look at (in months) e.g. look at the contract 2 and 4 months from now\n",
    "\n",
    "# Set lag variable params\n",
    "lag = 2 # Set lag time, 2 = prediction for 2 months\n",
    "lags_by_variable = {'cust_lag': [lag],\n",
    "                   'oil_lag': [lag],\n",
    "                   'fx_lag': [lag],\n",
    "                   'sentiment_lag': [lag]} # all lags must be greater than initial lag period\n",
    "\n",
    "# Sentiment cols_to_keep\n",
    "sentiment_cols = ['crude oil','crude oil_Count', 'soy', 'soy_Count', 'grains', 'ethanol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c747b753-898e-47d0-97e3-4107d9917b75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c747b753-898e-47d0-97e3-4107d9917b75",
    "outputId": "20b23272-119d-4b16-f2fc-82935f11750b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Customer DF...\n",
      "Length of Customer DF: 21696\n",
      "Lagging customer variables...\n",
      "Lagged customer df of len 21696 has been created containing 452 unique customers.\n",
      "Generating FUTURES DFs...\n",
      "Lagging variables...\n",
      "Created oils_df of length 48, crude_df of length 48 and fx_df of length 48.\n",
      "You are getting sentiment for: ['crude oil', 'crude oil_Count', 'soy', 'soy_Count', 'grains', 'ethanol']\n",
      "Created sentiment df of length 51\n",
      "Remove customer columns: ['%purchase_on_month', '%purchase_on_month_lag_2', 'purchase(t-1)_cust', 'purchases_on_month(t-1)_cust', 'purchase_quantity_on_month(t-1)_cust', 'cumulative_purchases_till_month(t-1)_cust', 'purchase_frequency(t-1)_cust', 'purchase_frequency_over_year(t-1)_cust', 'purchase_frequency_over_quarter(t-1)_cust', 'months_since_purchase(t-1)_cust', 'purchase', 'purchases_on_month', 'counter_party_code', 'commodity']\n",
      "Created combined_df for predection of len 21696 and first date 2018-01-31 00:00:00\n",
      "Length before dropping na (lag rows): 21696\n",
      "Length after dropping na (lag rows): 20340\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_split(lag = 1, # change this\n",
    "                                                        oil = oil, \n",
    "                                                        oil_file = oil_file, \n",
    "                                                        first_date =first_date, \n",
    "                                                        last_date = last_date,\n",
    "                                                        ema_lookback = ema_lookback, \n",
    "                                                        pct_lookback = pct_lookback, \n",
    "                                                        adv_months_list = adv_months_list, \n",
    "                                                        cols_to_keep = sentiment_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8416392-f3fb-4536-8ad0-8e699c19f4b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8416392-f3fb-4536-8ad0-8e699c19f4b6",
    "outputId": "430df3b5-26b3-497d-b172-6608e6156edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5563380281690141\n"
     ]
    }
   ],
   "source": [
    "# Load pickle model\n",
    "filename = 'best_model/soy_lgbm/lgbm_soy_1M.sav'\n",
    "best_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Make prediction and score\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print(test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d74392-a92a-4e80-9c21-fb625cf2127a",
   "metadata": {
    "id": "17d74392-a92a-4e80-9c21-fb625cf2127a",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 5. Coconut Oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd049da6-f343-47d9-8348-dc5f3bc98269",
   "metadata": {
    "id": "dd049da6-f343-47d9-8348-dc5f3bc98269"
   },
   "outputs": [],
   "source": [
    "# SET ALL PARAMS HERE\n",
    "# Random state\n",
    "random_state = 42\n",
    "\n",
    "# Oils\n",
    "oil = 'COCONUT OIL'# Set oil type\n",
    "remove_scenario = 'purchase' # if you want to predict sales, remove purchase. if predicting purchase, remove sales.\n",
    "first_date = '2018-01-01' # Get data up to this date for prediction\n",
    "last_date = '2022-01-01' # Last date at which customer data will cut off, default first_date = '2020-01-01'\n",
    "\n",
    "# Set lag variable params\n",
    "lag = 2 # Set lag time, 2 = prediction for 2 months\n",
    "lags_by_variable = {'cust_lag': [lag],\n",
    "                   'sentiment_lag': [lag]} # all lags must be greater than initial lag period\n",
    "\n",
    "# Sentiment cols_to_keep\n",
    "sentiment_cols = ['coconut oil', 'coconut oil_Count', 'crude oil', 'crude oil_Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0396b-67ab-40c1-8f8a-3bda59e6d63d",
   "metadata": {
    "id": "fdc0396b-67ab-40c1-8f8a-3bda59e6d63d"
   },
   "outputs": [],
   "source": [
    "def get_train_test_split(lag, oil, first_date, last_date, remove_scenario, cols_to_keep):\n",
    "       # Set lag variable params\n",
    "    lags_by_variable = {'cust_lag': [lag],\n",
    "                       'oil_lag': [lag],\n",
    "                       'fx_lag': [lag],\n",
    "                       'sentiment_lag': [lag]} # all lags must be greater than initial lag period\n",
    "\n",
    "    # Generate df\n",
    "    # Generate customer df\n",
    "    all_cust_monthly_df = prep.get_lagged_customer_df(oil = oil, \n",
    "                                                      first_date = first_date, \n",
    "                                                      last_date = last_date, \n",
    "                                                      lags_by_variable = lags_by_variable, \n",
    "                                                      verbose = False)\n",
    "\n",
    "    # Generate monthly sentiment df\n",
    "    sentiment = prep.get_sentiment_df(lags_by_variable = lags_by_variable, \n",
    "                                      cols_to_keep = sentiment_cols, \n",
    "                                      verbose = False)\n",
    "\n",
    "    # Remove either purchase or sales\n",
    "    remove = [v for v in all_cust_monthly_df.columns if remove_scenario in v] + ['counter_party_code', 'commodity']\n",
    "    print('Remove customer columns: {}'.format(remove))\n",
    "\n",
    "    all_cust_monthly_df_subset = all_cust_monthly_df.drop(remove, axis = 1)\n",
    "    combined_df = all_cust_monthly_df_subset.merge(sentiment, how = 'left', on = 'date') # merge customer to oils\n",
    "\n",
    "    # Prediction prep\n",
    "    # Keep columes with 'lag'\n",
    "    pred = combined_df.copy()\n",
    "\n",
    "    # Remove columns unrelated to prediction\n",
    "    remove = [v for v in pred.columns if 'volume' in v] + [v for v in pred.columns if 'ema' in v] \n",
    "    other_cols = ['date'] + remove\n",
    "    pred = pred.drop(other_cols, axis = 1)\n",
    "\n",
    "    # Drop na\n",
    "    pred = pred.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    # pred.info()\n",
    "    print('Length before dropping na (lag rows): {}'.format(len(pred)))\n",
    "\n",
    "    pred = pred.dropna() # remove lag empty rows\n",
    "    print('Length after dropping na (lag rows): {}'.format(len(pred)))\n",
    "\n",
    "    # # Change data types\n",
    "    pred = change_dtypes(pred)\n",
    "    \n",
    "    # Define Train-Test split\n",
    "    Y = pred['sale'].astype(int)\n",
    "    cols_to_drop = ['sale', 'sales_on_month'] # remove highly correlated features manually\n",
    "    X = pred.drop(cols_to_drop, axis = 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0828bb-9815-466f-beca-7ce0dce9ec8e",
   "metadata": {
    "id": "1a0828bb-9815-466f-beca-7ce0dce9ec8e",
    "outputId": "6c219843-9704-4e8c-df85-97bc634f3ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Customer DF...\n",
      "Length of Customer DF: 13872\n",
      "Lagging customer variables...\n",
      "Lagged customer df of len 13872 has been created containing 289 unique customers.\n",
      "You are getting sentiment for: ['coconut oil', 'coconut oil_Count', 'crude oil', 'crude oil_Count']\n",
      "Created sentiment df of length 51\n",
      "Remove customer columns: ['%purchase_on_month', '%purchase_on_month_lag_2', 'purchase(t-2)_cust', 'purchases_on_month(t-2)_cust', 'purchase_quantity_on_month(t-2)_cust', 'cumulative_purchases_till_month(t-2)_cust', 'purchase_frequency(t-2)_cust', 'purchase_frequency_over_year(t-2)_cust', 'purchase_frequency_over_quarter(t-2)_cust', 'months_since_purchase(t-2)_cust', 'purchase', 'purchases_on_month', 'counter_party_code', 'commodity']\n",
      "Length before dropping na (lag rows): 13872\n",
      "Length after dropping na (lag rows): 13294\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_split(lag = 2, # for prediction 2 months in advance\n",
    "                                                        oil = oil, \n",
    "                                                        first_date =first_date, \n",
    "                                                        last_date = last_date,\n",
    "                                                        remove_scenario = remove_scenario,\n",
    "                                                        cols_to_keep = sentiment_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb09d61d-74d0-41ec-8d82-2bd8f257a5ea",
   "metadata": {
    "id": "bb09d61d-74d0-41ec-8d82-2bd8f257a5ea",
    "outputId": "1906d5ed-de4c-4d74-8ead-09ee8ad86f71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5624543462381301\n"
     ]
    }
   ],
   "source": [
    "# Load pickle model\n",
    "filename = 'best_model/coconut_lgbm/lgbm_coconut_2M.sav'\n",
    "best_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Make prediction and score\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print(test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3490a22-5039-489d-991b-9adcb202342a",
   "metadata": {
    "id": "f3490a22-5039-489d-991b-9adcb202342a"
   },
   "source": [
    "## 6. Palm Kernel Oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65020fd2-74a6-47c4-b8b7-6674d1f62b4a",
   "metadata": {
    "id": "65020fd2-74a6-47c4-b8b7-6674d1f62b4a"
   },
   "outputs": [],
   "source": [
    "def get_train_test_split(lag, oil, oil_file, first_date, last_date, ema_lookback, pct_lookback, adv_months_list, cols_to_keep):\n",
    "       # Set lag variable params\n",
    "    lags_by_variable = {'cust_lag': [lag],\n",
    "                       'oil_lag': [lag],\n",
    "                       'fx_lag': [lag],\n",
    "                       'sentiment_lag': [lag]} # all lags must be greater than initial lag period\n",
    "\n",
    "    # Generate df\n",
    "    # Generate customer df\n",
    "    all_cust_monthly_df = prep.get_lagged_customer_df(oil = oil, \n",
    "                                                      first_date = first_date, \n",
    "                                                      last_date = last_date, \n",
    "                                                      lags_by_variable = lags_by_variable, \n",
    "                                                      verbose = False)\n",
    "\n",
    "    # Generate oils and fx dfs\n",
    "    oils_df, crude_df, fx_df = prep.get_lagged_futures_df(oil_file = oil_file, \n",
    "                                                          first_date = first_date, \n",
    "                                                          last_date = last_date, \n",
    "                                                          lags_by_variable = lags_by_variable,\n",
    "                                                          ema_lookback = ema_lookback,\n",
    "                                                          pct_lookback = pct_lookback,\n",
    "                                                          adv_months_list = adv_months_list,\n",
    "                                                          verbose = False)\n",
    "\n",
    "    # Generate monthly sentiment df\n",
    "    sentiment = prep.get_sentiment_df(lags_by_variable = lags_by_variable, \n",
    "                                      cols_to_keep = sentiment_cols, \n",
    "                                      verbose = False)\n",
    "\n",
    "    # Merge all dfs\n",
    "    combined_df = prep.merge_dfs(all_cust_monthly_df = all_cust_monthly_df, \n",
    "                                 remove_scenario = remove_scenario, \n",
    "                                 oils_df = oils_df, \n",
    "                                 crude_df = crude_df, \n",
    "                                 fx_df = fx_df, \n",
    "                                 sentiment_df = sentiment, \n",
    "                                 verbose = True)\n",
    "\n",
    "    # Prediction prep\n",
    "    # Keep columes with 'lag'\n",
    "    pred = combined_df.copy()\n",
    "\n",
    "    # Remove columns unrelated to prediction\n",
    "    remove =  [v for v in pred.columns if 'volume' in v] + [v for v in pred.columns if 'ema' in v] + [v for v in pred.columns if 'openinterest' in v] \n",
    "    other_cols = ['date'] + remove\n",
    "    pred = pred.drop(other_cols, axis = 1)\n",
    "\n",
    "    # Drop na\n",
    "    pred = pred.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    # pred.info()\n",
    "    print('Length before dropping na (lag rows): {}'.format(len(pred)))\n",
    "\n",
    "    pred = pred.dropna() # remove lag empty rows\n",
    "    print('Length after dropping na (lag rows): {}'.format(len(pred)))\n",
    "\n",
    "    # # Change data types\n",
    "    pred = change_dtypes(pred)\n",
    "    \n",
    "    # Define Train-Test split\n",
    "    Y = pred['sale'].astype(int)\n",
    "    cols_to_drop = ['sale', 'sales_on_month'] # remove highly correlated features manually\n",
    "    X = pred.drop(cols_to_drop, axis = 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a763c3d-0866-4dfa-9492-fe8b8a726f2d",
   "metadata": {
    "id": "4a763c3d-0866-4dfa-9492-fe8b8a726f2d"
   },
   "outputs": [],
   "source": [
    "# SET ALL PARAMS HERE\n",
    "# Random state\n",
    "random_state = 42\n",
    "\n",
    "# Oils\n",
    "oil = 'PALM KERNEL OIL'# Set oil type\n",
    "oil_file = 'data/palmkernaloil_futures.csv'\n",
    "remove_scenario = 'purchase' # if you want to predict sales, remove purchase. if predicting purchase, remove sales.\n",
    "first_date = '2018-01-01' # Get data up to this date for prediction\n",
    "last_date = '2022-01-01' # Last date at which customer data will cut off, default first_date = '2020-01-01'\n",
    "\n",
    "# Set futures lookback params\n",
    "ema_lookback = [2] # 1 month and 2 months\n",
    "pct_lookback = [2] # 1 month and 2 months\n",
    "adv_months_list = [2] # futures to look at (in months) e.g. look at the contract 2 and 4 months from now\n",
    "\n",
    "# Set lag variable params\n",
    "lag = 2 # Set lag time, 2 = prediction for 2 months\n",
    "lags_by_variable = {'cust_lag': [lag],\n",
    "                   'oil_lag': [lag],\n",
    "                   'fx_lag': [lag],\n",
    "                   'sentiment_lag': [lag]} # all lags must be greater than initial lag period\n",
    "\n",
    "# Sentiment cols_to_keep\n",
    "sentiment_cols = ['crude oil', 'crude oil_Count', 'palm oil', 'palm oil_Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "884df224-4fc9-42af-871b-2465014d7b27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "884df224-4fc9-42af-871b-2465014d7b27",
    "outputId": "2d9145e1-857f-45ae-dd89-b247e5f999b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Customer DF...\n",
      "Length of Customer DF: 19200\n",
      "Lagging customer variables...\n",
      "Lagged customer df of len 19200 has been created containing 400 unique customers.\n",
      "Generating FUTURES DFs...\n",
      "Lagging variables...\n",
      "Created oils_df of length 48, crude_df of length 48 and fx_df of length 48.\n",
      "You are getting sentiment for: ['crude oil', 'crude oil_Count', 'palm oil', 'palm oil_Count']\n",
      "Created sentiment df of length 51\n",
      "Remove customer columns: ['%purchase_on_month', '%purchase_on_month_lag_2', 'purchase(t-2)_cust', 'purchases_on_month(t-2)_cust', 'purchase_quantity_on_month(t-2)_cust', 'cumulative_purchases_till_month(t-2)_cust', 'purchase_frequency(t-2)_cust', 'purchase_frequency_over_year(t-2)_cust', 'purchase_frequency_over_quarter(t-2)_cust', 'months_since_purchase(t-2)_cust', 'purchase', 'purchases_on_month', 'counter_party_code', 'commodity']\n",
      "Created combined_df for predection of len 19200 and first date 2018-01-31 00:00:00\n",
      "Length before dropping na (lag rows): 19200\n",
      "Length after dropping na (lag rows): 17600\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_split(lag = 2, # change this\n",
    "                                                        oil = oil, \n",
    "                                                        oil_file = oil_file, \n",
    "                                                        first_date =first_date, \n",
    "                                                        last_date = last_date,\n",
    "                                                        ema_lookback = ema_lookback, \n",
    "                                                        pct_lookback = pct_lookback, \n",
    "                                                        adv_months_list = adv_months_list, \n",
    "                                                        cols_to_keep = sentiment_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07c7c3ed-7e80-4c62-a1e6-b442325a7b4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07c7c3ed-7e80-4c62-a1e6-b442325a7b4a",
    "outputId": "05a65a2f-976e-41ba-829b-807ffb5da23a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4718562874251497\n"
     ]
    }
   ],
   "source": [
    "# Load pickle model\n",
    "filename = 'best_model/palmkernel_lgbm/lgbm_palmkernel_2M.sav'\n",
    "best_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Make prediction and score\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print(test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd220a-d6b4-4627-a0e6-29a5f44a466c",
   "metadata": {
    "id": "f4bd220a-d6b4-4627-a0e6-29a5f44a466c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Best Classification Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
